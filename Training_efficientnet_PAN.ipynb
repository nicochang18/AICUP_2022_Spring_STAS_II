{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Provided by Prof. Lee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install monai\n",
    "!pip install torchvision\n",
    "!pip install -U Setuptools\n",
    "!pip install git+https://github.com/qubvel/segmentation_models.pytorch\n",
    "!pip install adabelief-pytorch==0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets widgetsnbextension\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import setuptools\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader #只有dataloader用torch的\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import create_test_image_2d, list_data_collate, decollate_batch\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChanneld,\n",
    "    AsDiscrete,\n",
    "    Compose,  \n",
    "    LoadImaged,\n",
    "    RandRotate90d,\n",
    "    ScaleIntensityd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    AsChannelFirstd,\n",
    "    Resized,\n",
    "    SaveImage,\n",
    "    Resize,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check MONAI configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monai.config.print_config()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -Set the Main Data Folder\n",
    "Data Folder Structure \n",
    "\n",
    "    YOUR PATH\n",
    "        ├Train_Images\n",
    "        └Train_Annotations_png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Data folder\n",
    "data_path = \"{YOUR PATH}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -obtain train data and validation data list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use index to apart train data and validation data.\n",
    "\n",
    "Create dictionary of images and annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of validation data\n",
    "val_num = 225\n",
    "\n",
    "# Load train files\n",
    "tempdir = data_path + \"Train_Images/\"\n",
    "train_images = sorted(glob(os.path.join(tempdir, \"*.jpg\")))\n",
    "\n",
    "tempdir = data_path + \"Train_Annotations_png/\"\n",
    "train_segs = sorted(glob(os.path.join(tempdir, \"*.png\")))\n",
    "\n",
    "# Training data\n",
    "train_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(train_images[val_num:], train_segs[val_num:])]\n",
    "print(f\" {len(train_images[val_num:])} train_images and {len(train_segs[val_num:])} train_segs\")\n",
    "\n",
    "# validation data\n",
    "val_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(train_images[:val_num], train_segs[:val_num])]\n",
    "print(f\" {len(train_images[:val_num])} val_images and {len(train_segs[:val_num])} val_segs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Trasform for image and segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms for image and segmentation\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "        AddChanneld(keys=[\"seg\"]),        \n",
    "        AsChannelFirstd(keys=[\"img\"]),\n",
    "        ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "        Resized(keys=[\"img\", \"seg\"], spatial_size=[800, 800]),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "        AddChanneld(keys=[\"seg\"]),        \n",
    "        AsChannelFirstd(keys=[\"img\"]),\n",
    "        ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "        Resized(keys=[\"img\", \"seg\"], spatial_size=[800, 800]),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check and visualize the transform results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset, data loader\n",
    "check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "check_loader = DataLoader(check_ds, batch_size=8, num_workers=12, collate_fn=list_data_collate)\n",
    "check_data = monai.utils.misc.first(check_loader)\n",
    "print(check_data[\"img\"].shape, check_data[\"seg\"].shape)\n",
    "\n",
    "\n",
    "plt.figure(\"visualize\",(16,64))\n",
    "for i in range(8):\n",
    "    plt.subplot(8,2,2*i+1)    \n",
    "    plt.imshow(check_data[\"img\"][i].permute(1,2,0))\n",
    "    plt.subplot(8,2,2*i+2)\n",
    "    plt.imshow(check_data[\"seg\"][i].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataLoader for train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a training data loader\n",
    "train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "# create a validation data loader\n",
    "val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=4, num_workers=4, collate_fn=list_data_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define metric and post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Environment\n",
    "Select GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Visualize Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image, cmap= 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model\n",
    ">Decoder : PAN\n",
    ">\n",
    ">Encoder : tu-tf_efficientnetv2_s_in21ft1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_params=dict(\n",
    "    pooling='avg',             # one of 'avg', 'max'\n",
    "    dropout=0.4,               # dropout ratio, default is None\n",
    "    activation=None,      # activation function, default is None\n",
    "    classes=1,                 # define number of output labels\n",
    ")\n",
    "\n",
    "encoder_name = 'tu-tf_efficientnetv2_s_in21ft1k'\n",
    "model = smp.PAN(encoder_name, aux_params=aux_params).to(device)\n",
    "model_name = encoder_name + '_PAN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -set optimizer & loss function\n",
    "Choose AdaBelief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adabelief_pytorch import AdaBelief\n",
    "optimizer = AdaBelief(model.parameters(), lr=1e-4, eps=1e-16, betas=(0.9, 0.98523), weight_decouple = True, rectify = False, weight_decay = 1e-4)\n",
    "loss_function = monai.losses.DiceLoss(sigmoid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -start traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### start a typical PyTorch training\n",
    "total_epochs = 64\n",
    "val_interval = 1\n",
    "best_metric = 100   # best model treshold\n",
    "best_metric_epoch = -1  # epoch of saved model\n",
    "epoch_loss_values = list()   \n",
    "metric_values = list()\n",
    "writer = SummaryWriter() \n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{total_epochs}\")\n",
    "\n",
    "    # start training\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    time_start = time.time()\n",
    "\n",
    "    for batch_data in enumerate(train_loader):\n",
    "        step += 1\n",
    "        time_end = time.time()\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size  \n",
    "        inputs, labels = batch_data[\"img\"].to(device), batch_data[\"seg\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, label = model(inputs) \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += float(loss.item())\n",
    "        # print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "        print(f\"{step}/{epoch_len} RUN   Use {'%.3f'%(time_end - time_start)}s   ||{'-'*step+'>>'+'-'*(epoch_len-step)}||\" , end='\\r')\n",
    "        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    local_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    train_loss.append(epoch_loss)  \n",
    "    print(\"\\n\", f\"{local_time} epoch {epoch + 1} training average loss: {epoch_loss:.4f}\")\n",
    "    print('1 Epoch Finished')\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_images = None\n",
    "            val_labels = None\n",
    "            val_outputs = None\n",
    "            val_step = 0\n",
    "            loss_val = 0\n",
    "\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)\n",
    "                val_outputs, val_out_label = model(val_images)\n",
    "                val_outputs = Resize([-1, 1716, 942])(val_outputs)\n",
    "                val_loss = monai.losses.DiceLoss(sigmoid=True)(val_outputs, val_labels)\n",
    "                loss_val += float(val_loss)\n",
    "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]                \n",
    "                    # val_labels = [post_trans(i) for i in decollate_batch(val_labels)]\n",
    "\n",
    "                # current validation\n",
    "                if  val_step == 16:\n",
    "                    print(\"val loss\", val_loss)\n",
    "                    visualize( \n",
    "                        image=val_images[0].cpu().permute(1,2,0), \n",
    "                        ground_truth_mask=val_labels[0].cpu().permute(1,2,0), \n",
    "                        predicted_mask=val_outputs[0].cpu().permute(1,2,0)\n",
    "                    )  \n",
    "                val_step += 1\n",
    "\n",
    "                # compute metric for current iteration\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "            # aggregate the final mean dice result\n",
    "            val_loss_ave = loss_val / val_step\n",
    "            print(\"val_loss = \", loss_val / val_step)\n",
    "\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "            metric_values.append(val_loss_ave)\n",
    "            val_loss.append(val_loss_ave)\n",
    "\n",
    "            if val_loss_ave < best_metric:\n",
    "                best_metric = val_loss_ave\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), f\"best_{total_epochs}_epochs_{model_name}.pth\")\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                \"current epoch: {} current val mean dice loss: {:.4f} best val mean dice loss: {:.4f} at epoch {}\".format(\n",
    "                    epoch + 1, val_loss_ave, best_metric, best_metric_epoch\n",
    "                )\n",
    "            )\n",
    "\n",
    "print(f\"training completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -load previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f\"{encoder_name}.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -reproduce validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "dice_metric.reset()\n",
    "with torch.no_grad():\n",
    "    val_images = None\n",
    "    val_labels = None\n",
    "    val_outputs = None\n",
    "    for val_data in val_loader:\n",
    "        val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)\n",
    "\n",
    "        val_outputs, val_out_label = model(val_images) #forward\n",
    "        val_outputs = Resize([-1, 1716, 942])(val_outputs)\n",
    "        val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]                \n",
    "\n",
    "        # compute metric for current iteration\n",
    "        dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "        print(dice_metric.aggregate())\n",
    "        \n",
    "    # aggregate the final mean dice result\n",
    "    metric = dice_metric.aggregate().item()\n",
    "    print(\"metric = \", metric)\n",
    "    # reset the status for next validation round\n",
    "    dice_metric.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Public Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "tempdir = data_path + \"Public_Image/\"\n",
    "test_images = sorted(glob.glob(os.path.join(tempdir, \"*.jpg\")))\n",
    "print(f\" {len(test_images)} test_images\")\n",
    "\n",
    "test_files = [{\"img\": img} for img in test_images[:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transform\n",
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\"]),   \n",
    "        AsChannelFirstd(keys=[\"img\"]),\n",
    "        ScaleIntensityd(keys=[\"img\"]),\n",
    "        Resized(keys=[\"img\"], spatial_size=[800, 800]),\n",
    "        EnsureTyped(keys=[\"img\"])\n",
    "    ]\n",
    ")\n",
    "test_ds = monai.data.Dataset(data=test_files, transform=test_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1,  collate_fn=list_data_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_data = sorted(glob.glob(tempdir + \"*.jpg\"))\n",
    "pub_data[0].split(\"/\")[-1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, test_data in enumerate(test_loader):\n",
    "        test_images = test_data[\"img\"].to(device)\n",
    "\n",
    "        test_outputs, test_out_label = model(test_images) #forward\n",
    "        test_outputs = Resize([-1, 1716, 942])(test_outputs)\n",
    "        \n",
    "        saverPD = SaveImage(output_dir=f\"{os.path.join(data_path, 'Predict/')}\", output_ext=\".png\", output_postfix=f\"{pub_data[i].split('/')[-1].split('.')[0]}\",scale=255,separate_folder=False)\n",
    "        saverPD(test_outputs[0].cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Private Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "tempdir = data_path + \"Private_Image/\"\n",
    "test_images = sorted(glob.glob(os.path.join(tempdir, \"*.jpg\")))\n",
    "print(f\" {len(test_images)} test_images\")\n",
    "\n",
    "test_files = [{\"img\": img} for img in test_images[:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transform\n",
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\"]),   \n",
    "        AsChannelFirstd(keys=[\"img\"]),\n",
    "        ScaleIntensityd(keys=[\"img\"]),\n",
    "        Resized(keys=[\"img\"], spatial_size=[800, 800]),\n",
    "        EnsureTyped(keys=[\"img\"])\n",
    "    ]\n",
    ")\n",
    "test_ds = monai.data.Dataset(data=test_files, transform=test_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1,  collate_fn=list_data_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pri_data = sorted(glob.glob(tempdir + \"*.jpg\"))\n",
    "pri_data[0].split(\"/\")[-1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, test_data in enumerate(test_loader):\n",
    "        test_images = test_data[\"img\"].to(device)\n",
    "\n",
    "        test_outputs, test_out_label = model(test_images) \n",
    "        test_outputs = Resize([-1, 1716, 942])(test_outputs)\n",
    "        \n",
    "        saverPD = SaveImage(output_dir=f\"{os.path.join(data_path, 'Predict/')}\", output_ext=\".png\", output_postfix=f\"{pri_data[i].split('/')[-1].split('.')[0]}\",scale=255,separate_folder=False)\n",
    "        saverPD(test_outputs[0].cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change File Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = sorted(glob.glob(f\"{os.path.join(data_path, 'Predict/')}\"))\n",
    "print(len(predict))\n",
    "\n",
    "for pred in predict:\n",
    "    os.rename(pred, os.path.join(*pred.split(\"/\")[:-1], pred.split(\"/\")[-1].split(\"_\", 1)[-1]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
